import networkx as nx
import matplotlib.pyplot as plt
import numpy as np

# ==========================================
# 1. 加载经典数据集 (Karate Club)
# ==========================================
# 空手道俱乐部图是图机器学习的 "Hello World"
G = nx.karate_club_graph()

print(f"Nodes: {G.number_of_nodes()}")
print(f"Edges: {G.number_of_edges()}")

# 可视化一下，感受结构
plt.figure(figsize=(10, 8))
pos = nx.spring_layout(G, seed=42) # 固定布局以便对比
nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=500)
plt.title("Zachary's Karate Club Graph")
plt.show()

# ==========================================
# 2. 计算不同的 Centrality (Graph as Matrix/Vector)
# ==========================================

# A. Degree Centrality (基于连接数量)
# NetworkX 返回的是归一化的度（度数 / (N-1)）
degree_dict = nx.degree_centrality(G)

# B. Betweenness Centrality (基于最短路径)
betweenness_dict = nx.betweenness_centrality(G)

# C. PageRank (基于递归权重 / Random Walk)
pagerank_dict = nx.pagerank(G, alpha=0.85) # alpha 是阻尼系数 (1 - teleport probability)

# ==========================================
# 3. 对比排序 (Compare Rankings)
# ==========================================
# 让我们看看不同指标下，谁是 "Top 5" 最重要的节点

def get_top_k(score_dict, k=5):
    # 按分数降序排列
    return sorted(score_dict.items(), key=lambda item: item[1], reverse=True)[:k]

print("\n--- Top 5 Nodes by Degree Centrality (Who knows the most people?) ---")
for node, score in get_top_k(degree_dict):
    print(f"Node {node}: {score:.4f}")

print("\n--- Top 5 Nodes by Betweenness Centrality (Who controls information flow?) ---")
for node, score in get_top_k(betweenness_dict):
    print(f"Node {node}: {score:.4f}")

print("\n--- Top 5 Nodes by PageRank (Who has the most authority?) ---")
for node, score in get_top_k(pagerank_dict):
    print(f"Node {node}: {score:.4f}")

# ==========================================
# 4. 深度洞察：为什么不同？
# ==========================================
# 观察输出你会发现：
# - Node 33 (教练) 和 Node 0 (管理员) 通常在所有指标上都很高。
# - 但是，请注意某些节点可能 Degree 不高，但 Betweenness 很高（因为它们连接了两个群体）。
# - PageRank 通常对这一小图的结果与 Degree 相似，但在大规模 Web 图中差异巨大。

# (进阶) 验证 PageRank 的随机游走解释
# 模拟一次随机游走，看看停留在 Node 33 的频率是否接近其 PageRank 值
print("\n--- Random Walk Simulation (Process View) ---")
num_steps = 10000
current_node = list(G.nodes())[0]
visits = {node: 0 for node in G.nodes()}

for _ in range(num_steps):
    visits[current_node] += 1
    neighbors = list(G.neighbors(current_node))
    if not neighbors: # Dead end
        current_node = list(G.nodes())[0]
    else:
        current_node = np.random.choice(neighbors)

total_visits = sum(visits.values())
simulated_pagerank_33 = visits[33] / total_visits
print(f"Simulated PageRank for Node 33: {simulated_pagerank_33:.4f}")
print(f"Actual PageRank for Node 33:    {pagerank_dict[33]:.4f}")
print("(Close enough? The simulation assumes no teleport, simple Random Walk)")